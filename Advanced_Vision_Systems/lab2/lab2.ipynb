{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "step=1\n",
    "for i in range (1 ,1100,step) :\n",
    "    I = cv2 . imread ( \"pedestrian/pedestrian/input/in%06d.jpg\" % i )\n",
    "    cv2.imshow (\"I\" ,I )\n",
    "    cv2.waitKey (10)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "step = 1\n",
    "kernel = np.ones((3,3), np.uint8)  # Jądro do operacji morfologicznych\n",
    "\n",
    "for i in range(300, 1100, step):\n",
    "    # Wczytaj obraz\n",
    "    I = cv2.imread(\"pedestrian/pedestrian/input/in%06d.jpg\" % i)\n",
    "\n",
    "\n",
    "\n",
    "    # Konwersja na obraz w skali szarości\n",
    "    gray = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "    (T , thresh ) = cv2.threshold (gray ,130 ,255 , cv2.THRESH_BINARY )\n",
    "    # Dylatacja\n",
    "    dilated = cv2.dilate(gray, kernel, iterations=1)\n",
    "\n",
    "    # Erozja\n",
    "    eroded = cv2.erode(gray, kernel, iterations=1)\n",
    "\n",
    "    abdsdiff=cv2.absdiff(eroded, dilated)\n",
    "\n",
    "    # Wyświetlenie oryginału, dylatacji i erozji\n",
    "    cv2.imshow(\"Original\", gray)\n",
    "    cv2.imshow(\"Dilated\", dilated)\n",
    "    cv2.imshow(\"Eroded\", eroded)\n",
    "    cv2.imshow(\"Diff eroded and dilated\",abdsdiff)\n",
    "    cv2.imshow(\"Binarization\",thresh)\n",
    "\n",
    "    # Czekaj na chwilę (10 ms) przed przejściem do następnego obrazu\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piękne 92% F1Score dla pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9077\n",
      "Recall: 0.9339\n",
      "F1-score: 0.9206\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "step = 1\n",
    "output_folder = \"pedestrian/pedestrian/output_masks\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "kernel = np.ones((5,5), np.uint8)  # szczerze nie wiem, czy 5,5 czy 7,7 jest lepszy\n",
    "kernel_dil=np.ones((3,3),np.uint8)\n",
    "\n",
    "# Inicjalizacja liczników\n",
    "TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "# Parametry detekcji ludzi\n",
    "MIN_AREA = 600   # Minimalna powierzchnia obiektu (ignoruje szum)\n",
    "MAX_AREA = 10000  # Maksymalna powierzchnia obiektu (pomija np. samochody)\n",
    "RATIO_THRESHOLD = 1.1  # Minimalny stosunek wysokości do szerokości dla ludzi (raczej nie potrzebne, w tym przypadku)\n",
    "\n",
    "# Zmienna przechowująca tło dla detekcji ruchu\n",
    "avg_frame = None  \n",
    "\n",
    "for i in range(300, 1100, step):\n",
    "    # Wczytaj obraz\n",
    "    I = cv2.imread(\"pedestrian/pedestrian/input/in%06d.jpg\" % i)\n",
    "\n",
    "    # Konwersja do skali szarości\n",
    "    gray = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Inicjalizacja tła dla detekcji ruchu (inicjalizacja tła dla pierwszej klatki)\n",
    "    if avg_frame is None:\n",
    "        avg_frame = np.float32(gray)\n",
    "    \n",
    "    # Aktualizacja średniej tła (to jest po to, ponieważ jak po prostu sprawdzało klatka po klatce ruch to nie wykrywało kogoś kto wolno chodzi, a tak to zbiera średnią z kilku klatek)\n",
    "    cv2.accumulateWeighted(gray, avg_frame, 0.005) #musi byc w float32 bo działa lepiej\n",
    "    background = cv2.convertScaleAbs(avg_frame)#powró do uint8\n",
    "\n",
    "    # Detekcja ruchu (różnica między aktualną klatką a tłem)\n",
    "    motion_mask = cv2.absdiff(gray, background)\n",
    "    _, motion_mask = cv2.threshold(motion_mask, 43, 255, cv2.THRESH_BINARY)\n",
    "    motion_mask = cv2.dilate(motion_mask, kernel_dil, iterations=1)  # Powiększenie obszaru ruchu\n",
    "\n",
    "    # Adaptacyjne progowanie\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 2)#lepszy niż otsu i ręcznie dobierany próg\n",
    "\n",
    "    # Operacja zamknięcia (zamyka przerwy w konturach ludzi)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2) #to jest dilatate i erosion w jednym\n",
    "\n",
    "    #edges = cv2.Canny(gray, 50, 150)\n",
    "    #morph = cv2.bitwise_and(morph, edges)\n",
    "\n",
    "\n",
    "    # Połączenie maski ruchu i progowania\n",
    "    combined_mask = cv2.bitwise_and(morph, motion_mask)\n",
    "    \n",
    "\n",
    "    #combined_mask =cv2.erode(combined_mask,kernel_dil,iterations=0)\n",
    "    combined_mask = cv2.dilate(combined_mask, kernel_dil, iterations=1)  # Pełniejsze sylwetki\n",
    "\n",
    "    combined_mask = cv2.medianBlur(combined_mask, 3)  # Redukuje szumy, stabilizuje maskę\n",
    "    mask_filename = os.path.join(output_folder, f\"mask_{i:06d}.png\")\n",
    "    cv2.imwrite(mask_filename, combined_mask)\n",
    "\n",
    "    # Znajdowanie składowych połączonych\n",
    "    retval, labels, stats, centroids = cv2.connectedComponentsWithStats(combined_mask, connectivity=8) #8-sąsiedztwo\n",
    "\n",
    "    I_VIS = I.copy()\n",
    "\n",
    "    # Wyrysowanie tylko obiektów przypominających ludzi\n",
    "    for pi in range(1, stats.shape[0]):  # Zaczynamy od 1, bo indeks 0 to tło\n",
    "        x, y, w, h, area = stats[pi]\n",
    "\n",
    "        # Filtrujemy obiekty na podstawie powierzchni i kształtu\n",
    "        if MIN_AREA < area < MAX_AREA and h > w * RATIO_THRESHOLD:\n",
    "            cv2.rectangle(I_VIS, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(I_VIS, f\"ID: {pi}\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "            cv2.putText(I_VIS, f\"{area} px\", (x, y + h + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    \n",
    "\n",
    "    # Wczytanie maski referencyjnej (groundtruth)\n",
    "    GTB = cv2.imread(f\"pedestrian/pedestrian/groundtruth/gt%06d.png\" % i, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if GTB is None:\n",
    "        print(f\"Brak groundtruth dla klatki {i}\")\n",
    "        continue  # Pomijamy brakujące klatki\n",
    "\n",
    "    # Konwersja groundtruth do binarnej postaci (upewniamy się, że tylko 0 i 255)\n",
    "    GTB[GTB > 0] = 255  \n",
    "\n",
    "    # Obliczenie metryk przy użyciu operacji macierzowych\n",
    "    TP += np.sum(np.logical_and((combined_mask == 255), (GTB == 255)))  # Prawdziwe pozytywy\n",
    "    FP += np.sum(np.logical_and((combined_mask == 255), (GTB == 0)))    # Fałszywe pozytywy\n",
    "    FN += np.sum(np.logical_and((combined_mask == 0), (GTB == 255)))    # Fałszywe negatywy\n",
    "    TN += np.sum(np.logical_and((combined_mask == 0), (GTB == 0)))      # Prawdziwe negatywy\n",
    "\n",
    "    good_diff=cv2.absdiff(GTB,combined_mask)\n",
    "\n",
    "    # Wyświetlanie przetworzonego obrazu\n",
    "    cv2.imshow(\"Processed Image\", I_VIS)\n",
    "    cv2.imshow(\"Motion Mask\",combined_mask)\n",
    "    cv2.imshow(\"Difference between motion mask and gtb\",good_diff)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "P = TP / (TP + FP) if (TP + FP) > 0 else 0  # Precision\n",
    "R = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall\n",
    "F1 = 2 * (P * R) / (P + R) if (P + R) > 0 else 0  # F1-score\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(f\"Precision: {P:.4f}\")\n",
    "print(f\"Recall: {R:.4f}\")\n",
    "print(f\"F1-score: {F1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8898\n",
      "Recall: 0.8779\n",
      "F1-score: 0.8838\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "step = 1\n",
    "output_folder = \"highway/highway/output_masks\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "kernel = np.ones((5,5), np.uint8)  # szczerze nie wiem, czy 5,5 czy 7,7 jest lepszy\n",
    "kernel_dil=np.ones((3,3),np.uint8)\n",
    "\n",
    "# Inicjalizacja liczników\n",
    "TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "# Parametry detekcji ludzi\n",
    "MIN_AREA = 1000   # Minimalna powierzchnia obiektu (ignoruje szum)\n",
    "MAX_AREA = 10000  # Maksymalna powierzchnia obiektu (pomija np. samochody)\n",
    "RATIO_THRESHOLD = 0.3  # Minimalny stosunek wysokości do szerokości dla ludzi (raczej nie potrzebne, w tym przypadku)\n",
    "\n",
    "# Zmienna przechowująca tło dla detekcji ruchu\n",
    "avg_frame = None  \n",
    "\n",
    "for i in range(470, 1700, step):\n",
    "    # Wczytaj obraz\n",
    "    I = cv2.imread(\"highway/highway/input/in%06d.jpg\" % i)\n",
    "\n",
    "    # Konwersja do skali szarości\n",
    "    gray = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Inicjalizacja tła dla detekcji ruchu (inicjalizacja tła dla pierwszej klatki)\n",
    "    if avg_frame is None:\n",
    "        avg_frame = np.float32(gray)\n",
    "    \n",
    "    # Aktualizacja średniej tła (to jest po to, ponieważ jak po prostu sprawdzało klatka po klatce ruch to nie wykrywało kogoś kto wolno chodzi, a tak to zbiera średnią z kilku klatek)\n",
    "    cv2.accumulateWeighted(gray, avg_frame, 0.01) #musi byc w float32 bo działa lepiej\n",
    "    background = cv2.convertScaleAbs(avg_frame)#powró do uint8\n",
    "\n",
    "    # Detekcja ruchu (różnica między aktualną klatką a tłem)\n",
    "    motion_mask = cv2.absdiff(gray, background)\n",
    "    _, motion_mask = cv2.threshold(motion_mask, 58, 255, cv2.THRESH_BINARY)\n",
    "    motion_mask = cv2.dilate(motion_mask, kernel_dil, iterations=1)  # Powiększenie obszaru ruchu\n",
    "\n",
    "    # Adaptacyjne progowanie\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 2)#lepszy niż otsu i ręcznie dobierany próg\n",
    "\n",
    "    # Operacja zamknięcia (zamyka przerwy w konturach ludzi)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2) #to jest dilatate i erosion w jednym\n",
    "\n",
    "    #edges = cv2.Canny(gray, 50, 150)\n",
    "    #morph = cv2.bitwise_and(morph, edges)\n",
    "\n",
    "\n",
    "    # Połączenie maski ruchu i progowania\n",
    "    combined_mask = cv2.bitwise_and(morph, motion_mask)\n",
    "    \n",
    "\n",
    "    #combined_mask =cv2.erode(combined_mask,kernel_dil,iterations=0)\n",
    "    combined_mask = cv2.dilate(combined_mask, kernel_dil, iterations=1)  # Pełniejsze sylwetki\n",
    "\n",
    "    combined_mask = cv2.medianBlur(combined_mask, 3)  # Redukuje szumy, stabilizuje maskę\n",
    "    mask_filename = os.path.join(output_folder, f\"mask_{i:06d}.png\")\n",
    "    cv2.imwrite(mask_filename, combined_mask)\n",
    "\n",
    "    # Znajdowanie składowych połączonych\n",
    "    retval, labels, stats, centroids = cv2.connectedComponentsWithStats(combined_mask, connectivity=8) #8-sąsiedztwo\n",
    "\n",
    "    I_VIS = I.copy()\n",
    "\n",
    "    # Wyrysowanie tylko obiektów przypominających ludzi\n",
    "    for pi in range(1, stats.shape[0]):  # Zaczynamy od 1, bo indeks 0 to tło\n",
    "        x, y, w, h, area = stats[pi]\n",
    "\n",
    "        # Filtrujemy obiekty na podstawie powierzchni i kształtu\n",
    "        if MIN_AREA < area < MAX_AREA and h > w * RATIO_THRESHOLD:\n",
    "            cv2.rectangle(I_VIS, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(I_VIS, f\"ID: {pi}\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "            cv2.putText(I_VIS, f\"{area} px\", (x, y + h + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    \n",
    "\n",
    "    # Wczytanie maski referencyjnej (groundtruth)\n",
    "    GTB = cv2.imread(f\"highway/highway/groundtruth/gt%06d.png\" % i, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if GTB is None:\n",
    "        print(f\"Brak groundtruth dla klatki {i}\")\n",
    "        continue  # Pomijamy brakujące klatki\n",
    "\n",
    "    # Konwersja groundtruth do binarnej postaci (upewniamy się, że tylko 0 i 255)\n",
    "    GTB[GTB > 0] = 255  \n",
    "\n",
    "    # Obliczenie metryk przy użyciu operacji macierzowych\n",
    "    TP += np.sum(np.logical_and((combined_mask == 255), (GTB == 255)))  # Prawdziwe pozytywy\n",
    "    FP += np.sum(np.logical_and((combined_mask == 255), (GTB == 0)))    # Fałszywe pozytywy\n",
    "    FN += np.sum(np.logical_and((combined_mask == 0), (GTB == 255)))    # Fałszywe negatywy\n",
    "    TN += np.sum(np.logical_and((combined_mask == 0), (GTB == 0)))      # Prawdziwe negatywy\n",
    "\n",
    "    good_diff=cv2.absdiff(GTB,combined_mask)\n",
    "\n",
    "    # Wyświetlanie przetworzonego obrazu\n",
    "    cv2.imshow(\"Processed Image\", I_VIS)\n",
    "    cv2.imshow(\"Motion Mask\",combined_mask)\n",
    "    cv2.imshow(\"Difference between motion mask and gtb\",good_diff)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "P = TP / (TP + FP) if (TP + FP) > 0 else 0  # Precision\n",
    "R = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall\n",
    "F1 = 2 * (P * R) / (P + R) if (P + R) > 0 else 0  # F1-score\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(f\"Precision: {P:.4f}\")\n",
    "print(f\"Recall: {R:.4f}\")\n",
    "print(f\"F1-score: {F1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8346\n",
      "Recall: 0.9017\n",
      "F1-score: 0.8669\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "step = 15\n",
    "output_folder = \"office/office/output_masks\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "kernel = np.ones((5,5), np.uint8)  # szczerze nie wiem, czy 5,5 czy 7,7 jest lepszy\n",
    "kernel_dil=np.ones((3,3),np.uint8)\n",
    "\n",
    "# Inicjalizacja liczników\n",
    "TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "# Parametry detekcji ludzi\n",
    "MIN_AREA = 5500   # Minimalna powierzchnia obiektu (ignoruje szum)\n",
    "MAX_AREA = 12000  # Maksymalna powierzchnia obiektu (pomija np. samochody)\n",
    "RATIO_THRESHOLD = 1.1  # Minimalny stosunek wysokości do szerokości dla ludzi (raczej nie potrzebne, w tym przypadku)\n",
    "\n",
    "# Zmienna przechowująca tło dla detekcji ruchu\n",
    "avg_frame = None  \n",
    "\n",
    "for i in range(570, 2050, step):\n",
    "    # Wczytaj obraz\n",
    "    I = cv2.imread(\"office/office/input/in%06d.jpg\" % i)\n",
    "\n",
    "    # Konwersja do skali szarości\n",
    "    gray = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Inicjalizacja tła dla detekcji ruchu (inicjalizacja tła dla pierwszej klatki)\n",
    "    if avg_frame is None:\n",
    "        avg_frame = np.float32(gray)\n",
    "    \n",
    "    # Aktualizacja średniej tła (to jest po to, ponieważ jak po prostu sprawdzało klatka po klatce ruch to nie wykrywało kogoś kto wolno chodzi, a tak to zbiera średnią z kilku klatek)\n",
    "    cv2.accumulateWeighted(gray, avg_frame, 0.01) #musi byc w float32 bo działa lepiej\n",
    "    background = cv2.convertScaleAbs(avg_frame)#powró do uint8\n",
    "\n",
    "    # Detekcja ruchu (różnica między aktualną klatką a tłem)\n",
    "    motion_mask = cv2.absdiff(gray, background)\n",
    "    _, motion_mask = cv2.threshold(motion_mask, 45, 255, cv2.THRESH_BINARY)\n",
    "    motion_mask = cv2.dilate(motion_mask, kernel_dil, iterations=1)  # Powiększenie obszaru ruchu\n",
    "\n",
    "    # Adaptacyjne progowanie\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 2)#lepszy niż otsu i ręcznie dobierany próg\n",
    "\n",
    "    # Operacja zamknięcia (zamyka przerwy w konturach ludzi)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2) #to jest dilatate i erosion w jednym\n",
    "\n",
    "    #edges = cv2.Canny(gray, 50, 150)\n",
    "    #morph = cv2.bitwise_and(morph, edges)\n",
    "\n",
    "\n",
    "    # Połączenie maski ruchu i progowania\n",
    "    combined_mask = cv2.bitwise_and(morph, motion_mask)\n",
    "    \n",
    "\n",
    "    #combined_mask =cv2.erode(combined_mask,kernel_dil,iterations=0)\n",
    "    combined_mask = cv2.dilate(combined_mask, kernel_dil, iterations=1)  # Pełniejsze sylwetki\n",
    "\n",
    "    combined_mask = cv2.medianBlur(combined_mask, 3)  # Redukuje szumy, stabilizuje maskę\n",
    "    mask_filename = os.path.join(output_folder, f\"mask_{i:06d}.png\")\n",
    "    cv2.imwrite(mask_filename, combined_mask)\n",
    "\n",
    "    # Znajdowanie składowych połączonych\n",
    "    retval, labels, stats, centroids = cv2.connectedComponentsWithStats(combined_mask, connectivity=8) #8-sąsiedztwo\n",
    "\n",
    "    I_VIS = I.copy()\n",
    "\n",
    "    # Wyrysowanie tylko obiektów przypominających ludzi\n",
    "    for pi in range(1, stats.shape[0]):  # Zaczynamy od 1, bo indeks 0 to tło\n",
    "        x, y, w, h, area = stats[pi]\n",
    "\n",
    "        # Filtrujemy obiekty na podstawie powierzchni i kształtu\n",
    "        if MIN_AREA < area < MAX_AREA and h > w * RATIO_THRESHOLD:\n",
    "            cv2.rectangle(I_VIS, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(I_VIS, f\"ID: {pi}\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "            cv2.putText(I_VIS, f\"{area} px\", (x, y + h + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    \n",
    "\n",
    "    # Wczytanie maski referencyjnej (groundtruth)\n",
    "    GTB = cv2.imread(f\"office/office/groundtruth/gt%06d.png\" % i, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if GTB is None:\n",
    "        print(f\"Brak groundtruth dla klatki {i}\")\n",
    "        continue  # Pomijamy brakujące klatki\n",
    "\n",
    "    # Konwersja groundtruth do binarnej postaci (upewniamy się, że tylko 0 i 255)\n",
    "    GTB[GTB > 0] = 255  \n",
    "\n",
    "    # Obliczenie metryk przy użyciu operacji macierzowych\n",
    "    TP += np.sum(np.logical_and((combined_mask == 255), (GTB == 255)))  # Prawdziwe pozytywy\n",
    "    FP += np.sum(np.logical_and((combined_mask == 255), (GTB == 0)))    # Fałszywe pozytywy\n",
    "    FN += np.sum(np.logical_and((combined_mask == 0), (GTB == 255)))    # Fałszywe negatywy\n",
    "    TN += np.sum(np.logical_and((combined_mask == 0), (GTB == 0)))      # Prawdziwe negatywy\n",
    "\n",
    "    good_diff=cv2.absdiff(GTB,combined_mask)\n",
    "\n",
    "    # Wyświetlanie przetworzonego obrazu\n",
    "    cv2.imshow(\"Processed Image\", I_VIS)\n",
    "    cv2.imshow(\"Motion Mask\",combined_mask)\n",
    "    cv2.imshow(\"Difference between motion mask and gtb\",good_diff)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "P = TP / (TP + FP) if (TP + FP) > 0 else 0  # Precision\n",
    "R = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall\n",
    "F1 = 2 * (P * R) / (P + R) if (P + R) > 0 else 0  # F1-score\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(f\"Precision: {P:.4f}\")\n",
    "print(f\"Recall: {R:.4f}\")\n",
    "print(f\"F1-score: {F1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
